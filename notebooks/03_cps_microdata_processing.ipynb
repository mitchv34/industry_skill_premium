{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS Microdata Processing\n",
    "\n",
    "**Processing CPS microdata using Python and Polars**\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook processes raw CPS data:\n",
    "- Loads raw CPS data (4.4M observations)\n",
    "- Applies all sample selection filters\n",
    "- Creates demographic cells\n",
    "- Aggregates to skilled/unskilled\n",
    "- Outputs processed labor series\n",
    "\n",
    "## Why Polars?\n",
    "\n",
    "- **Speed**: 5-10x faster than pandas on large data\n",
    "- **Memory**: More efficient with 4.4M rows\n",
    "- **API**: Similar to pandas, easy to learn\n",
    "\n",
    "## Outputs\n",
    "\n",
    "This notebook produces:\n",
    "- `labor_totl.csv` - Aggregate time series\n",
    "- `labor_by_group.csv` - Demographic cell data\n",
    "- Sample selection statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.33.0\n",
      "\n",
      "Data paths:\n",
      "  Raw: /Users/mitchv34/Work/industry_skill_premium/data/raw\n",
      "  Processed: /Users/mitchv34/Work/industry_skill_premium/data/proc\n",
      "\n",
      "Raw CPS file exists: True\n"
     ]
    }
   ],
   "source": [
    "# Install polars if needed (uncomment)\n",
    "# !pip install polars\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Polars version:\", pl.__version__)\n",
    "\n",
    "# Paths\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_RAW = ROOT / 'data' / 'raw'\n",
    "DATA_PROC = ROOT / 'data' / 'proc'\n",
    "\n",
    "print(f\"\\nData paths:\")\n",
    "print(f\"  Raw: {DATA_RAW}\")\n",
    "print(f\"  Processed: {DATA_PROC}\")\n",
    "print(f\"\\nRaw CPS file exists: {(DATA_RAW / 'cps_00022.csv').exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw CPS Data\n",
    "\n",
    "Loading 4.4M observations from IPUMS CPS extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw CPS data...\n",
      "File: /Users/mitchv34/Work/industry_skill_premium/data/raw/cps_00022.csv\n",
      "Size: 0.31 GB\n",
      "\n",
      "Loaded: 4,358,291 rows × 21 columns\n",
      "Memory: 555.6 MB\n",
      "\n",
      "Schema:\n",
      "Schema({'YEAR': Int64, 'HFLAG': Int64, 'ASECWTH': Float64, 'CPI99': Float64, 'ASECWT': Float64, 'AGE': Int64, 'SEX': Int64, 'RACE': Int64, 'EMPSTAT': Int64, 'OCC2010': String, 'OCC1990': String, 'IND1990': String, 'AHRSWORKT': Int64, 'EDUC': Int64, 'HIGRADE': Int64, 'EDUC99': String, 'CLASSWLY': Int64, 'WKSWORK1': String, 'WKSWORK2': Int64, 'UHRSWORKLY': String, 'INCWAGE': Int64})\n",
      "\n",
      "HFLAG distribution:\n",
      "shape: (3, 2)\n",
      "┌───────┬─────────┐\n",
      "│ HFLAG ┆ count   │\n",
      "│ ---   ┆ ---     │\n",
      "│ i64   ┆ u32     │\n",
      "╞═══════╪═════════╡\n",
      "│ null  ┆ 4269321 │\n",
      "│ 0     ┆ 62152   │\n",
      "│ 1     ┆ 26818   │\n",
      "└───────┴─────────┘\n",
      "\n",
      "First few rows:\n",
      "shape: (5, 21)\n",
      "┌──────┬───────┬─────────┬───────┬───┬──────────┬──────────┬────────────┬─────────┐\n",
      "│ YEAR ┆ HFLAG ┆ ASECWTH ┆ CPI99 ┆ … ┆ WKSWORK1 ┆ WKSWORK2 ┆ UHRSWORKLY ┆ INCWAGE │\n",
      "│ ---  ┆ ---   ┆ ---     ┆ ---   ┆   ┆ ---      ┆ ---      ┆ ---        ┆ ---     │\n",
      "│ i64  ┆ i64   ┆ f64     ┆ f64   ┆   ┆ str      ┆ i64      ┆ str        ┆ i64     │\n",
      "╞══════╪═══════╪═════════╪═══════╪═══╪══════════╪══════════╪════════════╪═════════╡\n",
      "│ 1962 ┆ null  ┆ 6427.43 ┆ 5.572 ┆ … ┆ null     ┆ 3        ┆ null       ┆ 1500    │\n",
      "│ 1962 ┆ null  ┆ 6588.56 ┆ 5.572 ┆ … ┆ null     ┆ 0        ┆ null       ┆ 2300    │\n",
      "│ 1962 ┆ null  ┆ 3560.24 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "│ 1962 ┆ null  ┆ 3560.24 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "│ 1962 ┆ null  ┆ 3202.72 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "└──────┴───────┴─────────┴───────┴───┴──────────┴──────────┴────────────┴─────────┘\n",
      "\n",
      "Loaded: 4,358,291 rows × 21 columns\n",
      "Memory: 555.6 MB\n",
      "\n",
      "Schema:\n",
      "Schema({'YEAR': Int64, 'HFLAG': Int64, 'ASECWTH': Float64, 'CPI99': Float64, 'ASECWT': Float64, 'AGE': Int64, 'SEX': Int64, 'RACE': Int64, 'EMPSTAT': Int64, 'OCC2010': String, 'OCC1990': String, 'IND1990': String, 'AHRSWORKT': Int64, 'EDUC': Int64, 'HIGRADE': Int64, 'EDUC99': String, 'CLASSWLY': Int64, 'WKSWORK1': String, 'WKSWORK2': Int64, 'UHRSWORKLY': String, 'INCWAGE': Int64})\n",
      "\n",
      "HFLAG distribution:\n",
      "shape: (3, 2)\n",
      "┌───────┬─────────┐\n",
      "│ HFLAG ┆ count   │\n",
      "│ ---   ┆ ---     │\n",
      "│ i64   ┆ u32     │\n",
      "╞═══════╪═════════╡\n",
      "│ null  ┆ 4269321 │\n",
      "│ 0     ┆ 62152   │\n",
      "│ 1     ┆ 26818   │\n",
      "└───────┴─────────┘\n",
      "\n",
      "First few rows:\n",
      "shape: (5, 21)\n",
      "┌──────┬───────┬─────────┬───────┬───┬──────────┬──────────┬────────────┬─────────┐\n",
      "│ YEAR ┆ HFLAG ┆ ASECWTH ┆ CPI99 ┆ … ┆ WKSWORK1 ┆ WKSWORK2 ┆ UHRSWORKLY ┆ INCWAGE │\n",
      "│ ---  ┆ ---   ┆ ---     ┆ ---   ┆   ┆ ---      ┆ ---      ┆ ---        ┆ ---     │\n",
      "│ i64  ┆ i64   ┆ f64     ┆ f64   ┆   ┆ str      ┆ i64      ┆ str        ┆ i64     │\n",
      "╞══════╪═══════╪═════════╪═══════╪═══╪══════════╪══════════╪════════════╪═════════╡\n",
      "│ 1962 ┆ null  ┆ 6427.43 ┆ 5.572 ┆ … ┆ null     ┆ 3        ┆ null       ┆ 1500    │\n",
      "│ 1962 ┆ null  ┆ 6588.56 ┆ 5.572 ┆ … ┆ null     ┆ 0        ┆ null       ┆ 2300    │\n",
      "│ 1962 ┆ null  ┆ 3560.24 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "│ 1962 ┆ null  ┆ 3560.24 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "│ 1962 ┆ null  ┆ 3202.72 ┆ 5.572 ┆ … ┆ null     ┆ 2        ┆ null       ┆ 0       │\n",
      "└──────┴───────┴─────────┴───────┴───┴──────────┴──────────┴────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Load raw CPS with Polars (ensure HFLAG is numeric)\n",
    "print(\"Loading raw CPS data...\")\n",
    "print(f\"File: {cps_file}\")\n",
    "print(f\"Size: {cps_file.stat().st_size / (1024**3):.2f} GB\")\n",
    "\n",
    "# Read with explicit dtype for HFLAG (nullable Int64)\n",
    "df = pl.read_csv(cps_file, dtypes={'HFLAG': pl.Int64})\n",
    "\n",
    "print(f\"\\nLoaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Memory: {df.estimated_size('mb'):.1f} MB\")\n",
    "\n",
    "# Confirm HFLAG is numeric and show its distribution\n",
    "print(\"\\nSchema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nHFLAG distribution:\")\n",
    "print(df.group_by('HFLAG').count().sort('HFLAG'))\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview\n",
    "\n",
    "Examine the raw CPS data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RAW CPS DATA OVERVIEW\n",
      "======================================================================\n",
      "\n",
      "Shape: (4358291, 21)\n",
      "\n",
      "Years: 1962 - 2022\n",
      "Unique years: 61\n",
      "\n",
      "Observations per year:\n",
      "shape: (10, 2)\n",
      "┌──────┬────────┐\n",
      "│ YEAR ┆ count  │\n",
      "│ ---  ┆ ---    │\n",
      "│ i64  ┆ u32    │\n",
      "╞══════╪════════╡\n",
      "│ 2013 ┆ 89666  │\n",
      "│ 2014 ┆ 88970  │\n",
      "│ 2015 ┆ 88874  │\n",
      "│ 2016 ┆ 83162  │\n",
      "│ 2017 ┆ 84143  │\n",
      "│ 2018 ┆ 81555  │\n",
      "│ 2019 ┆ 82429  │\n",
      "│ 2020 ┆ 70559  │\n",
      "│ 2021 ┆ 71631  │\n",
      "│ 2022 ┆ 138709 │\n",
      "└──────┴────────┘\n",
      "\n",
      "Data types:\n",
      "Schema({'YEAR': Int64, 'HFLAG': Int64, 'ASECWTH': Float64, 'CPI99': Float64, 'ASECWT': Float64, 'AGE': Int64, 'SEX': Int64, 'RACE': Int64, 'EMPSTAT': Int64, 'OCC2010': String, 'OCC1990': String, 'IND1990': String, 'AHRSWORKT': Int64, 'EDUC': Int64, 'HIGRADE': Int64, 'EDUC99': String, 'CLASSWLY': Int64, 'WKSWORK1': String, 'WKSWORK2': Int64, 'UHRSWORKLY': String, 'INCWAGE': Int64})\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(\"=\"*70)\n",
    "print(\"RAW CPS DATA OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nYears: {df['YEAR'].min()} - {df['YEAR'].max()}\")\n",
    "print(f\"Unique years: {df['YEAR'].n_unique()}\")\n",
    "print(f\"\\nObservations per year:\")\n",
    "print(df.group_by('YEAR').count().sort('YEAR').tail(10))\n",
    "print(f\"\\nData types:\")\n",
    "print(df.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Selection\n",
    "\n",
    "Apply sample selection filters to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLE SELECTION PIPELINE\n",
      "======================================================================\n",
      "\n",
      "1. Raw CPS extract: 4,358,291 (100.0%)\n",
      "2. Valid ASECWT: 4,219,582 (100.0%)\n",
      "   Applied 2014 weight adjustment\n",
      "3. Wage/salary workers: 3,658,059 (100.0%)\n",
      "4. Weeks worked reported: 3,658,059 (100.0%)\n",
      "5. Age 16-70: 3,658,059 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "Current sample: 3,658,059 observations\n",
      "======================================================================\n",
      "3. Wage/salary workers: 3,658,059 (100.0%)\n",
      "4. Weeks worked reported: 3,658,059 (100.0%)\n",
      "5. Age 16-70: 3,658,059 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "Current sample: 3,658,059 observations\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Track sample size at each step\n",
    "sample_flow = []\n",
    "\n",
    "def log_sample(step, df_current):\n",
    "    n = len(df_current)\n",
    "    pct = (n / len(df)) * 100\n",
    "    sample_flow.append({'Step': step, 'N': n, 'Percent': pct})\n",
    "    print(f\"{step}: {n:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLE SELECTION PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Initial\n",
    "log_sample(\"1. Raw CPS extract\", df)\n",
    "\n",
    "# Filter 1: Valid survey weights\n",
    "df = df.filter(pl.col('ASECWT').is_not_null())\n",
    "log_sample(\"2. Valid ASECWT\", df)\n",
    "\n",
    "# Filter 2: 2014 CPS redesign adjustment\n",
    "# Adjust weights for 2014 sample\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col('YEAR') == 2014)\n",
    "    .then(pl.col('ASECWT') * (5/8 * (1 - pl.col('HFLAG')) + 3/8 * pl.col('HFLAG')))\n",
    "    .otherwise(pl.col('ASECWT'))\n",
    "    .alias('ASECWT')\n",
    "])\n",
    "print(\"   Applied 2014 weight adjustment\")\n",
    "\n",
    "# Filter 3: Employment type (wage/salary workers only)\n",
    "# CLASSWLY: 20=private, 22=federal, 24=state, 25=local, 27=nonprofit, 28=public\n",
    "kept_classes = [20, 22, 24, 25, 27, 28]\n",
    "df = df.filter(pl.col('CLASSWLY').is_in(kept_classes))\n",
    "log_sample(\"3. Wage/salary workers\", df)\n",
    "\n",
    "# Filter 4: Weeks worked\n",
    "df = df.filter(pl.col('WKSWORK2') != 0)\n",
    "log_sample(\"4. Weeks worked reported\", df)\n",
    "\n",
    "# Filter 5: Age range (16-70)\n",
    "df = df.filter((pl.col('AGE') >= 16) & (pl.col('AGE') <= 70))\n",
    "log_sample(\"5. Age 16-70\", df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Current sample: {len(df):,} observations\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Education Recoding\n",
    "\n",
    "Harmonize education variables (HIGRADE pre-1992, EDUC99 post-1992) into 4 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recoding education...\n",
      "6. Education reported: 3,608,182 (100.0%)\n",
      "\n",
      "Education distribution:\n",
      "shape: (4, 2)\n",
      "┌────────┬─────────┐\n",
      "│ EDUCAT ┆ count   │\n",
      "│ ---    ┆ ---     │\n",
      "│ str    ┆ u32     │\n",
      "╞════════╪═════════╡\n",
      "│ BH     ┆ 575634  │\n",
      "│ CG     ┆ 939366  │\n",
      "│ HS     ┆ 1162688 │\n",
      "│ SC     ┆ 930494  │\n",
      "└────────┴─────────┘\n",
      "6. Education reported: 3,608,182 (100.0%)\n",
      "\n",
      "Education distribution:\n",
      "shape: (4, 2)\n",
      "┌────────┬─────────┐\n",
      "│ EDUCAT ┆ count   │\n",
      "│ ---    ┆ ---     │\n",
      "│ str    ┆ u32     │\n",
      "╞════════╪═════════╡\n",
      "│ BH     ┆ 575634  │\n",
      "│ CG     ┆ 939366  │\n",
      "│ HS     ┆ 1162688 │\n",
      "│ SC     ┆ 930494  │\n",
      "└────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Education recoding functions (robust to string/NA inputs)\n",
    "def recode_higrade(val):\n",
    "    '''Recode HIGRADE (pre-1992) to 4 categories'''\n",
    "    try:\n",
    "        if val is None:\n",
    "            return None\n",
    "        v = float(val)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if v < 31 or v == 999:\n",
    "        return None\n",
    "    elif 31 <= v < 150:\n",
    "        return 'BH'  # Below High School\n",
    "    elif v == 150:\n",
    "        return 'HS'  # High School\n",
    "    elif 150 < v < 190:\n",
    "        return 'SC'  # Some College\n",
    "    elif v >= 190:\n",
    "        return 'CG'  # College Graduate\n",
    "    return None\n",
    "\n",
    "def recode_educ99(val):\n",
    "    '''Recode EDUC99 (post-1992) to 4 categories'''\n",
    "    try:\n",
    "        if val is None:\n",
    "            return None\n",
    "        v = float(val)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if v <= 1:\n",
    "        return None\n",
    "    elif 1 < v < 9:\n",
    "        return 'BH'\n",
    "    elif v == 10:\n",
    "        return 'HS'\n",
    "    elif 10 < v < 15:\n",
    "        return 'SC'\n",
    "    elif v >= 15:\n",
    "        return 'CG'\n",
    "    return None\n",
    "\n",
    "# Apply recoding (specify return dtype so Polars can infer UDF output)\n",
    "print(\"Recoding education...\")\n",
    "df = df.with_columns([\n",
    "    pl.col('HIGRADE').map_elements(recode_higrade, return_dtype=pl.Utf8).alias('EDUCAT_1'),\n",
    "    pl.col('EDUC99').map_elements(recode_educ99, return_dtype=pl.Utf8).alias('EDUCAT_2')\n",
    "])\n",
    "\n",
    "# Combine: use HIGRADE if available, else EDUC99\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col('EDUCAT_1').is_not_null())\n",
    "    .then(pl.col('EDUCAT_1'))\n",
    "    .otherwise(pl.col('EDUCAT_2'))\n",
    "    .alias('EDUCAT')\n",
    "])\n",
    "\n",
    "# Filter: education reported\n",
    "df = df.filter(pl.col('EDUCAT').is_not_null())\n",
    "log_sample(\"6. Education reported\", df)\n",
    "\n",
    "print(f\"\\nEducation distribution:\")\n",
    "print(df.group_by('EDUCAT').count().sort('EDUCAT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Filters - Full-Time Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking WKSWORK1 and UHRSWORKLY availability (preview):\n",
      "shape: (20, 4)\n",
      "┌──────┬──────────────┬────────────────┬───────┐\n",
      "│ YEAR ┆ has_wkswork1 ┆ has_uhrsworkly ┆ total │\n",
      "│ ---  ┆ ---          ┆ ---            ┆ ---   │\n",
      "│ i64  ┆ u32          ┆ u32            ┆ u32   │\n",
      "╞══════╪══════════════╪════════════════╪═══════╡\n",
      "│ 1962 ┆ 0            ┆ 0              ┆ 20512 │\n",
      "│ 1964 ┆ 0            ┆ 0              ┆ 21650 │\n",
      "│ 1965 ┆ 0            ┆ 0              ┆ 22047 │\n",
      "│ 1966 ┆ 0            ┆ 0              ┆ 47886 │\n",
      "│ 1967 ┆ 0            ┆ 0              ┆ 30897 │\n",
      "│ …    ┆ …            ┆ …              ┆ …     │\n",
      "│ 1978 ┆ 55934        ┆ 55934          ┆ 55934 │\n",
      "│ 1979 ┆ 56931        ┆ 56931          ┆ 56931 │\n",
      "│ 1980 ┆ 67163        ┆ 67163          ┆ 67163 │\n",
      "│ 1981 ┆ 67117        ┆ 67117          ┆ 67117 │\n",
      "│ 1982 ┆ 58809        ┆ 58809          ┆ 58809 │\n",
      "└──────┴──────────────┴────────────────┴───────┘\n",
      "\n",
      "Filtering to years with complete data (1976+)...\n",
      "7. Years with complete data (1976+): 3,085,970 (100.0%)\n",
      "8. Has weeks/hours/wage reported: 3,085,970 (100.0%)\n",
      "8. Has weeks/hours/wage reported: 3,085,970 (100.0%)\n",
      "9. >= 40 weeks worked: 2,705,164 (100.0%)\n",
      "10. >= 30 hours/week: 2,453,330 (100.0%)\n",
      "9. >= 40 weeks worked: 2,705,164 (100.0%)\n",
      "10. >= 30 hours/week: 2,453,330 (100.0%)\n",
      "11. Positive hours worked: 2,453,330 (100.0%)\n",
      "12. Wage floor: 2,444,580 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "FINAL SAMPLE: 2,444,580 observations\n",
      "======================================================================\n",
      "11. Positive hours worked: 2,453,330 (100.0%)\n",
      "12. Wage floor: 2,444,580 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "FINAL SAMPLE: 2,444,580 observations\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Coerce work/earnings vars to numeric and continue filtering (fixes string-vs-number ComputeError)\n",
    "\n",
    "print(\"Checking WKSWORK1 and UHRSWORKLY availability (preview):\")\n",
    "print(availability.sort('YEAR').head(20))\n",
    "\n",
    "# Keep years with complete data (1976+)\n",
    "print(\"\\nFiltering to years with complete data (1976+)...\")\n",
    "df = df.filter(pl.col('YEAR') >= 1976)\n",
    "log_sample(\"7. Years with complete data (1976+)\", df)\n",
    "\n",
    "# Robust converter for stringy columns\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        if x is None:\n",
    "            return None\n",
    "        s = str(x).strip()\n",
    "        if s == '' or s.upper() in {'NA', 'N/A', 'NULL', '.'}:\n",
    "            return None\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Cast columns to floats (nullable) so numeric comparisons work\n",
    "df = df.with_columns([\n",
    "    pl.col('WKSWORK1').map_elements(_to_float, return_dtype=pl.Float64).alias('WKSWORK1'),\n",
    "    pl.col('UHRSWORKLY').map_elements(_to_float, return_dtype=pl.Float64).alias('UHRSWORKLY'),\n",
    "    pl.col('INCWAGE').map_elements(_to_float, return_dtype=pl.Float64).alias('INCWAGE'),\n",
    "])\n",
    "\n",
    "# Drop rows missing these key variables (we skip imputation for 1963-75)\n",
    "df = df.filter(\n",
    "    pl.col('WKSWORK1').is_not_null()\n",
    "    & pl.col('UHRSWORKLY').is_not_null()\n",
    "    & pl.col('INCWAGE').is_not_null()\n",
    ")\n",
    "log_sample(\"8. Has weeks/hours/wage reported\", df)\n",
    "\n",
    "# Apply weeks/hours thresholds\n",
    "df = df.filter(pl.col('WKSWORK1') >= 40)\n",
    "log_sample(\"9. >= 40 weeks worked\", df)\n",
    "\n",
    "df = df.filter(pl.col('UHRSWORKLY') >= 30)  # minimum hours threshold\n",
    "log_sample(\"10. >= 30 hours/week\", df)\n",
    "\n",
    "# Compute HOURS_WORKED and hourly wage, guarding against zero hours\n",
    "df = df.with_columns([\n",
    "    (pl.col('WKSWORK1') * pl.col('UHRSWORKLY')).alias('HOURS_WORKED')\n",
    "])\n",
    "\n",
    "# Remove zero-hours to avoid division by zero\n",
    "df = df.filter(pl.col('HOURS_WORKED') > 0)\n",
    "log_sample(\"11. Positive hours worked\", df)\n",
    "\n",
    "df = df.with_columns([\n",
    "    (pl.col('INCWAGE') / pl.col('HOURS_WORKED')).alias('WAGE')\n",
    "])\n",
    "\n",
    "# Wage floor: >= half minimum wage in 1999 dollars\n",
    "# Min wage 1999 = $5.65/hr, so floor = $5.65 / 4 = 1.4125\n",
    "df = df.filter((pl.col('WAGE') * pl.col('CPI99')) >= (5.65 / 4))\n",
    "log_sample(\"12. Wage floor\", df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"FINAL SAMPLE: {len(df):,} observations\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demographic Cell Construction\n",
    "\n",
    "Create 264 cells: Age (11) × Race (3) × Sex (2) × Education (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating demographic cells...\n",
      "\n",
      "Created 264 unique demographic cells\n",
      "\n",
      "Skill distribution:\n",
      "shape: (2, 2)\n",
      "┌───────┬─────────┐\n",
      "│ SKILL ┆ count   │\n",
      "│ ---   ┆ ---     │\n",
      "│ str   ┆ u32     │\n",
      "╞═══════╪═════════╡\n",
      "│ U     ┆ 1696010 │\n",
      "│ S     ┆ 748570  │\n",
      "└───────┴─────────┘\n",
      "\n",
      "Example GROUP IDs:\n",
      "shape: (10, 6)\n",
      "┌────────┬────────┬──────────┬───────────┬─────┬───────┐\n",
      "│ GROUP  ┆ EDUCAT ┆ AGEGROUP ┆ RACEGROUP ┆ SEX ┆ SKILL │\n",
      "│ ---    ┆ ---    ┆ ---      ┆ ---       ┆ --- ┆ ---   │\n",
      "│ str    ┆ str    ┆ str      ┆ str       ┆ i64 ┆ str   │\n",
      "╞════════╪════════╪══════════╪═══════════╪═════╪═══════╡\n",
      "│ BH09W1 ┆ BH     ┆ 09       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH10W2 ┆ BH     ┆ 10       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH06W1 ┆ BH     ┆ 06       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH06W2 ┆ BH     ┆ 06       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH09W2 ┆ BH     ┆ 09       ┆ W         ┆ 2   ┆ U     │\n",
      "│ HS05W1 ┆ HS     ┆ 05       ┆ W         ┆ 1   ┆ U     │\n",
      "│ HS05W2 ┆ HS     ┆ 05       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH07W1 ┆ BH     ┆ 07       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH01W1 ┆ BH     ┆ 01       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH08W2 ┆ BH     ┆ 08       ┆ W         ┆ 2   ┆ U     │\n",
      "└────────┴────────┴──────────┴───────────┴─────┴───────┘\n",
      "\n",
      "Created 264 unique demographic cells\n",
      "\n",
      "Skill distribution:\n",
      "shape: (2, 2)\n",
      "┌───────┬─────────┐\n",
      "│ SKILL ┆ count   │\n",
      "│ ---   ┆ ---     │\n",
      "│ str   ┆ u32     │\n",
      "╞═══════╪═════════╡\n",
      "│ U     ┆ 1696010 │\n",
      "│ S     ┆ 748570  │\n",
      "└───────┴─────────┘\n",
      "\n",
      "Example GROUP IDs:\n",
      "shape: (10, 6)\n",
      "┌────────┬────────┬──────────┬───────────┬─────┬───────┐\n",
      "│ GROUP  ┆ EDUCAT ┆ AGEGROUP ┆ RACEGROUP ┆ SEX ┆ SKILL │\n",
      "│ ---    ┆ ---    ┆ ---      ┆ ---       ┆ --- ┆ ---   │\n",
      "│ str    ┆ str    ┆ str      ┆ str       ┆ i64 ┆ str   │\n",
      "╞════════╪════════╪══════════╪═══════════╪═════╪═══════╡\n",
      "│ BH09W1 ┆ BH     ┆ 09       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH10W2 ┆ BH     ┆ 10       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH06W1 ┆ BH     ┆ 06       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH06W2 ┆ BH     ┆ 06       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH09W2 ┆ BH     ┆ 09       ┆ W         ┆ 2   ┆ U     │\n",
      "│ HS05W1 ┆ HS     ┆ 05       ┆ W         ┆ 1   ┆ U     │\n",
      "│ HS05W2 ┆ HS     ┆ 05       ┆ W         ┆ 2   ┆ U     │\n",
      "│ BH07W1 ┆ BH     ┆ 07       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH01W1 ┆ BH     ┆ 01       ┆ W         ┆ 1   ┆ U     │\n",
      "│ BH08W2 ┆ BH     ┆ 08       ┆ W         ┆ 2   ┆ U     │\n",
      "└────────┴────────┴──────────┴───────────┴─────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Age groups\n",
    "def recode_age(age):\n",
    "    if age <= 20:\n",
    "        return '01'\n",
    "    elif age <= 25:\n",
    "        return '02'\n",
    "    elif age <= 30:\n",
    "        return '03'\n",
    "    elif age <= 35:\n",
    "        return '04'\n",
    "    elif age <= 40:\n",
    "        return '05'\n",
    "    elif age <= 45:\n",
    "        return '06'\n",
    "    elif age <= 50:\n",
    "        return '07'\n",
    "    elif age <= 55:\n",
    "        return '08'\n",
    "    elif age <= 60:\n",
    "        return '09'\n",
    "    elif age <= 65:\n",
    "        return '10'\n",
    "    elif age <= 70:\n",
    "        return '11'\n",
    "    return None\n",
    "\n",
    "# Race groups\n",
    "def recode_race(race):\n",
    "    if race == 100:\n",
    "        return 'W'  # White\n",
    "    elif race == 200:\n",
    "        return 'B'  # Black\n",
    "    else:\n",
    "        return 'O'  # Other\n",
    "\n",
    "print(\"Creating demographic cells...\")\n",
    "df = df.with_columns([\n",
    "    pl.col('AGE').map_elements(recode_age).alias('AGEGROUP'),\n",
    "    pl.col('RACE').map_elements(recode_race).alias('RACEGROUP')\n",
    "])\n",
    "\n",
    "# Create GROUP ID\n",
    "df = df.with_columns([\n",
    "    (pl.col('EDUCAT') + pl.col('AGEGROUP') + pl.col('RACEGROUP') + pl.col('SEX').cast(str)).alias('GROUP')\n",
    "])\n",
    "\n",
    "# Define skill\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col('EDUCAT') == 'CG')\n",
    "    .then(pl.lit('S'))\n",
    "    .otherwise(pl.lit('U'))\n",
    "    .alias('SKILL')\n",
    "])\n",
    "\n",
    "print(f\"\\nCreated {df['GROUP'].n_unique()} unique demographic cells\")\n",
    "print(f\"\\nSkill distribution:\")\n",
    "print(df.group_by('SKILL').count())\n",
    "\n",
    "# Show example groups\n",
    "print(f\"\\nExample GROUP IDs:\")\n",
    "print(df.select(['GROUP', 'EDUCAT', 'AGEGROUP', 'RACEGROUP', 'SEX', 'SKILL']).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Aggregation to Skill Groups\n",
    "\n",
    "Aggregation steps:\n",
    "1. Normalize weights within year\n",
    "2. Calculate group-level averages\n",
    "3. Weight by 1980 wages (efficiency units)\n",
    "4. Aggregate to skilled/unskilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Normalizing weights...\n",
      "Step 2: Group-level aggregation...\n",
      "\n",
      "Grouped data shape: (11871, 7)\n",
      "shape: (5, 7)\n",
      "┌──────┬────────┬───────┬───────────┬──────────┬──────────┬───────────┐\n",
      "│ YEAR ┆ GROUP  ┆ SKILL ┆ L_group   ┆ W_group  ┆ weight   ┆ W_avg     │\n",
      "│ ---  ┆ ---    ┆ ---   ┆ ---       ┆ ---      ┆ ---      ┆ ---       │\n",
      "│ i64  ┆ str    ┆ str   ┆ f64       ┆ f64      ┆ f64      ┆ f64       │\n",
      "╞══════╪════════╪═══════╪═══════════╪══════════╪══════════╪═══════════╡\n",
      "│ 2010 ┆ CG04B2 ┆ S     ┆ 6.28491   ┆ 0.066399 ┆ 0.002938 ┆ 22.599057 │\n",
      "│ 1993 ┆ BH09B2 ┆ U     ┆ 0.583293  ┆ 0.002143 ┆ 0.000293 ┆ 7.306791  │\n",
      "│ 2011 ┆ SC01W1 ┆ U     ┆ 3.716078  ┆ 0.021768 ┆ 0.00197  ┆ 11.049046 │\n",
      "│ 2012 ┆ HS05W2 ┆ U     ┆ 16.849905 ┆ 0.121382 ┆ 0.008199 ┆ 14.805023 │\n",
      "│ 2015 ┆ CG05O1 ┆ S     ┆ 8.137883  ┆ 0.168469 ┆ 0.003499 ┆ 48.151359 │\n",
      "└──────┴────────┴───────┴───────────┴──────────┴──────────┴───────────┘\n",
      "\n",
      "Grouped data shape: (11871, 7)\n",
      "shape: (5, 7)\n",
      "┌──────┬────────┬───────┬───────────┬──────────┬──────────┬───────────┐\n",
      "│ YEAR ┆ GROUP  ┆ SKILL ┆ L_group   ┆ W_group  ┆ weight   ┆ W_avg     │\n",
      "│ ---  ┆ ---    ┆ ---   ┆ ---       ┆ ---      ┆ ---      ┆ ---       │\n",
      "│ i64  ┆ str    ┆ str   ┆ f64       ┆ f64      ┆ f64      ┆ f64       │\n",
      "╞══════╪════════╪═══════╪═══════════╪══════════╪══════════╪═══════════╡\n",
      "│ 2010 ┆ CG04B2 ┆ S     ┆ 6.28491   ┆ 0.066399 ┆ 0.002938 ┆ 22.599057 │\n",
      "│ 1993 ┆ BH09B2 ┆ U     ┆ 0.583293  ┆ 0.002143 ┆ 0.000293 ┆ 7.306791  │\n",
      "│ 2011 ┆ SC01W1 ┆ U     ┆ 3.716078  ┆ 0.021768 ┆ 0.00197  ┆ 11.049046 │\n",
      "│ 2012 ┆ HS05W2 ┆ U     ┆ 16.849905 ┆ 0.121382 ┆ 0.008199 ┆ 14.805023 │\n",
      "│ 2015 ┆ CG05O1 ┆ S     ┆ 8.137883  ┆ 0.168469 ┆ 0.003499 ┆ 48.151359 │\n",
      "└──────┴────────┴───────┴───────────┴──────────┴──────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Normalize weights within year\n",
    "print(\"Step 1: Normalizing weights...\")\n",
    "df = df.with_columns([\n",
    "    (pl.col('ASECWT') / pl.col('ASECWT').sum().over('YEAR')).alias('ASECWT_norm')\n",
    "])\n",
    "\n",
    "# Step 2: Group-level aggregation\n",
    "print(\"Step 2: Group-level aggregation...\")\n",
    "grouped = df.group_by(['YEAR', 'GROUP', 'SKILL']).agg([\n",
    "    (pl.col('HOURS_WORKED') * pl.col('ASECWT_norm')).sum().alias('L_group'),\n",
    "    (pl.col('WAGE') * pl.col('ASECWT_norm')).sum().alias('W_group'),\n",
    "    pl.col('ASECWT_norm').sum().alias('weight')\n",
    "])\n",
    "\n",
    "# Average wage per group\n",
    "grouped = grouped.with_columns([\n",
    "    (pl.col('W_group') / pl.col('weight')).alias('W_avg')\n",
    "])\n",
    "\n",
    "print(f\"\\nGrouped data shape: {grouped.shape}\")\n",
    "print(grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Getting 1980 wage weights...\n",
      "\n",
      "Groups with 1980 wages: 11513\n",
      "\n",
      "Step 4: Aggregating to skilled/unskilled...\n",
      "\n",
      "Aggregated shape: (92, 5)\n",
      "shape: (10, 5)\n",
      "┌──────┬───────┬──────────────┬───────────────┬───────────┐\n",
      "│ YEAR ┆ SKILL ┆ L            ┆ W_weighted    ┆ W         │\n",
      "│ ---  ┆ ---   ┆ ---          ┆ ---           ┆ ---       │\n",
      "│ i64  ┆ str   ┆ f64          ┆ f64           ┆ f64       │\n",
      "╞══════╪═══════╪══════════════╪═══════════════╪═══════════╡\n",
      "│ 1992 ┆ S     ┆ 5498.849678  ┆ 100365.81522  ┆ 18.252147 │\n",
      "│ 2000 ┆ U     ┆ 10207.449805 ┆ 151590.138364 ┆ 14.850932 │\n",
      "│ 1999 ┆ S     ┆ 6248.425895  ┆ 158109.681696 ┆ 25.303922 │\n",
      "│ 1986 ┆ U     ┆ 10383.511659 ┆ 100577.412923 ┆ 9.686262  │\n",
      "│ 1981 ┆ U     ┆ 10681.963668 ┆ 80870.325718  ┆ 7.570736  │\n",
      "│ 2007 ┆ S     ┆ 6907.211659  ┆ 232277.614291 ┆ 33.628275 │\n",
      "│ 2021 ┆ U     ┆ 7915.117845  ┆ 196482.7332   ┆ 24.823728 │\n",
      "│ 2008 ┆ S     ┆ 7091.396314  ┆ 236752.045725 ┆ 33.385815 │\n",
      "│ 1990 ┆ S     ┆ 5376.742807  ┆ 92124.205951  ┆ 17.133832 │\n",
      "│ 2011 ┆ U     ┆ 9156.02657   ┆ 178723.935115 ┆ 19.519814 │\n",
      "└──────┴───────┴──────────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get 1980 wages for weighting\n",
    "print(\"Step 3: Getting 1980 wage weights...\")\n",
    "\n",
    "# Get 1980 wages by group\n",
    "wages_1980 = grouped.filter(pl.col('YEAR') == 1980).select(['GROUP', 'W_avg']).rename({'W_avg': 'W_1980'})\n",
    "\n",
    "# Join back\n",
    "grouped = grouped.join(wages_1980, on='GROUP', how='left')\n",
    "\n",
    "# Create efficiency units\n",
    "grouped = grouped.with_columns([\n",
    "    (pl.col('L_group') * pl.col('W_1980')).alias('L_efficiency')\n",
    "])\n",
    "\n",
    "print(f\"\\nGroups with 1980 wages: {grouped.filter(pl.col('W_1980').is_not_null()).shape[0]}\")\n",
    "\n",
    "# Step 4: Aggregate to skills\n",
    "print(\"\\nStep 4: Aggregating to skilled/unskilled...\")\n",
    "labor_series = grouped.group_by(['YEAR', 'SKILL']).agg([\n",
    "    pl.col('L_efficiency').sum().alias('L'),\n",
    "    (pl.col('W_avg') * pl.col('L_efficiency')).sum().alias('W_weighted')\n",
    "])\n",
    "\n",
    "# Calculate average wages\n",
    "labor_series = labor_series.with_columns([\n",
    "    (pl.col('W_weighted') / pl.col('L')).alias('W')\n",
    "])\n",
    "\n",
    "print(f\"\\nAggregated shape: {labor_series.shape}\")\n",
    "print(labor_series.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Final Output\n",
    "\n",
    "Pivot to wide format and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final output format...\n",
      "\n",
      "Final output shape: (46, 7)\n",
      "\n",
      "Columns: ['YEAR', 'L_S', 'L_U', 'W_S', 'W_U', 'SKILL_PREMIUM', 'LABOR_INPUT_RATIO']\n",
      "\n",
      "First few years:\n",
      "shape: (10, 7)\n",
      "┌──────┬─────────────┬──────────────┬───────────┬──────────┬───────────────┬───────────────────┐\n",
      "│ YEAR ┆ L_S         ┆ L_U          ┆ W_S       ┆ W_U      ┆ SKILL_PREMIUM ┆ LABOR_INPUT_RATIO │\n",
      "│ ---  ┆ ---         ┆ ---          ┆ ---       ┆ ---      ┆ ---           ┆ ---               │\n",
      "│ i64  ┆ f64         ┆ f64          ┆ f64       ┆ f64      ┆ f64           ┆ f64               │\n",
      "╞══════╪═════════════╪══════════════╪═══════════╪══════════╪═══════════════╪═══════════════════╡\n",
      "│ 1976 ┆ 4056.453573 ┆ 11183.259719 ┆ 7.590603  ┆ 5.212479 ┆ 1.456237      ┆ 0.362726          │\n",
      "│ 1977 ┆ 4089.863988 ┆ 11113.543068 ┆ 8.062356  ┆ 5.563399 ┆ 1.449178      ┆ 0.368007          │\n",
      "│ 1978 ┆ 4103.251214 ┆ 11130.908084 ┆ 8.605731  ┆ 5.947687 ┆ 1.446904      ┆ 0.368636          │\n",
      "│ 1979 ┆ 4184.476323 ┆ 11023.536982 ┆ 9.074995  ┆ 6.369111 ┆ 1.424845      ┆ 0.379595          │\n",
      "│ 1980 ┆ 4251.898502 ┆ 10870.166214 ┆ 9.81946   ┆ 6.980281 ┆ 1.406743      ┆ 0.391153          │\n",
      "│ 1981 ┆ 4392.507949 ┆ 10681.963668 ┆ 10.621468 ┆ 7.570736 ┆ 1.402964      ┆ 0.411208          │\n",
      "│ 1982 ┆ 4601.385927 ┆ 10534.36924  ┆ 11.807972 ┆ 8.233535 ┆ 1.434132      ┆ 0.436797          │\n",
      "│ 1983 ┆ 4937.88584  ┆ 10222.899571 ┆ 12.583784 ┆ 8.637295 ┆ 1.456913      ┆ 0.483022          │\n",
      "│ 1984 ┆ 4964.362402 ┆ 10286.000677 ┆ 13.097825 ┆ 8.892747 ┆ 1.472866      ┆ 0.482633          │\n",
      "│ 1985 ┆ 5020.184872 ┆ 10395.136162 ┆ 13.950806 ┆ 9.26873  ┆ 1.505148      ┆ 0.482936          │\n",
      "└──────┴─────────────┴──────────────┴───────────┴──────────┴───────────────┴───────────────────┘\n",
      "\n",
      "✅ Saved to: /Users/mitchv34/Work/industry_skill_premium/data/proc/labor_totl_python.csv\n"
     ]
    }
   ],
   "source": [
    "# Pivot to wide format\n",
    "print(\"Creating final output format...\")\n",
    "\n",
    "# Separate skilled and unskilled\n",
    "labor_wide = labor_series.pivot(\n",
    "    values=['L', 'W'],\n",
    "    index='YEAR',\n",
    "    columns='SKILL'\n",
    ").sort('YEAR')\n",
    "\n",
    "# Rename columns\n",
    "labor_wide = labor_wide.rename({\n",
    "    'L_S': 'L_S',\n",
    "    'L_U': 'L_U',\n",
    "    'W_S': 'W_S', \n",
    "    'W_U': 'W_U'\n",
    "})\n",
    "\n",
    "# Calculate ratios\n",
    "labor_wide = labor_wide.with_columns([\n",
    "    (pl.col('W_S') / pl.col('W_U')).alias('SKILL_PREMIUM'),\n",
    "    (pl.col('L_S') / pl.col('L_U')).alias('LABOR_INPUT_RATIO')\n",
    "])\n",
    "\n",
    "print(f\"\\nFinal output shape: {labor_wide.shape}\")\n",
    "print(f\"\\nColumns: {labor_wide.columns}\")\n",
    "print(f\"\\nFirst few years:\")\n",
    "print(labor_wide.head(10))\n",
    "\n",
    "# Save\n",
    "output_file = DATA_PROC / 'labor_totl_python.csv'\n",
    "labor_wide.write_csv(output_file)\n",
    "print(f\"\\n✅ Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### What We Did\n",
    "\n",
    "✅ Loaded raw CPS (4.4M observations)  \n",
    "✅ Applied all sample selection filters  \n",
    "✅ Recoded education variables  \n",
    "✅ Created 264 demographic cells  \n",
    "✅ Aggregated using 1980 wage weights  \n",
    "✅ Produced skilled/unskilled series  \n",
    "\n",
    "### Output\n",
    "\n",
    "**File**: `labor_totl_python.csv`\n",
    "\n",
    "Contains:\n",
    "- `YEAR`: 1976-2018 (1963-75 needs imputation)\n",
    "- `L_S`, `L_U`: Labor input (efficiency units)\n",
    "- `W_S`, `W_U`: Average wages (1999 dollars)\n",
    "- `SKILL_PREMIUM`: W_S / W_U\n",
    "- `LABOR_INPUT_RATIO`: L_S / L_U\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Implement 1963-75 imputation for full time series\n",
    "2. Add industry segmentation\n",
    "3. Run analysis notebooks to visualize and analyze output\n",
    "\n",
    "---\n",
    "\n",
    "**Processing complete!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Labor Share Table for Manuscript\n",
    "\n",
    "Create Table~\\ref{tab:labor_share_by_industry} showing initial level, final level, change, and growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 industries in crosswalk\n",
      "\n",
      "Sample mappings:\n",
      "  110C: Farms\n",
      "  113F: Forestry, fishing, and related activities\n",
      "  2110: Oil and gas extraction\n",
      "  2120: Mining, except oil and gas\n",
      "  2130: Support activities for mining\n",
      "\n",
      "✅ Processed 56 industries\n",
      "\n",
      "First 10 industries by initial labor share:\n",
      "                                        Industry   Code  Initial Year  \\\n",
      "52                                         711AS  711AS          1987   \n",
      "44  Computer systems design and related services   5415          1987   \n",
      "49                                           621    621          1987   \n",
      "51                                           624    624          1987   \n",
      "6                                             23     23          1987   \n",
      "42                                Legal services   5411          1987   \n",
      "48                                            61     61          1987   \n",
      "50                                         622HO  622HO          1987   \n",
      "12                                           323    323          1987   \n",
      "46                                           561    561          1987   \n",
      "\n",
      "    Initial LS  Final Year  Final LS    Change  Annual Growth (%)  \n",
      "52    0.971122        2018  0.767032 -0.204091          -0.758157  \n",
      "44    0.963178        2018  0.860729 -0.102450          -0.362114  \n",
      "49    0.936090        2018  0.867736 -0.068354          -0.244296  \n",
      "51    0.932601        2018  0.949570  0.016969           0.058185  \n",
      "6     0.924041        2018  0.797903 -0.126139          -0.472333  \n",
      "42    0.917883        2018  0.664050 -0.253833          -1.038802  \n",
      "48    0.917083        2018  0.813342 -0.103742          -0.386499  \n",
      "50    0.896072        2018  0.856303 -0.039769          -0.146332  \n",
      "12    0.876653        2018  0.664788 -0.211865          -0.888426  \n",
      "46    0.864621        2018  0.820754 -0.043867          -0.167821  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_IND = ROOT / 'data' / 'proc' / 'ind'\n",
    "CROSSWALK = ROOT / 'data' / 'cross_walk.csv'\n",
    "\n",
    "# Load crosswalk for industry names\n",
    "crosswalk = pd.read_csv(CROSSWALK)\n",
    "code_to_name = dict(zip(crosswalk['code_bea'].str.upper(), crosswalk['ind_desc']))\n",
    "\n",
    "print(f\"Found {len(crosswalk)} industries in crosswalk\")\n",
    "print(f\"\\nSample mappings:\")\n",
    "for code, name in list(code_to_name.items())[:5]:\n",
    "    print(f\"  {code}: {name}\")\n",
    "\n",
    "# Process each industry file\n",
    "results = []\n",
    "\n",
    "for file in sorted(DATA_IND.glob('*.csv')):\n",
    "    try:\n",
    "        # Get industry code from filename\n",
    "        ind_code = file.stem.upper()\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Check if L_SHARE column exists\n",
    "        if 'L_SHARE' not in df.columns:\n",
    "            print(f\"Warning: {file.name} missing L_SHARE column\")\n",
    "            continue\n",
    "        \n",
    "        # Get initial and final years\n",
    "        df = df.sort_values('YEAR')\n",
    "        initial_year = df['YEAR'].min()\n",
    "        final_year = df['YEAR'].max()\n",
    "        \n",
    "        # Get labor share values\n",
    "        initial_ls = df.loc[df['YEAR'] == initial_year, 'L_SHARE'].values[0]\n",
    "        final_ls = df.loc[df['YEAR'] == final_year, 'L_SHARE'].values[0]\n",
    "        \n",
    "        # Calculate change and annualized growth rate\n",
    "        change = final_ls - initial_ls\n",
    "        years = final_year - initial_year\n",
    "        if years > 0 and initial_ls > 0:\n",
    "            annual_growth = ((final_ls / initial_ls) ** (1/years) - 1) * 100\n",
    "        else:\n",
    "            annual_growth = np.nan\n",
    "        \n",
    "        # Get industry name from crosswalk\n",
    "        industry_name = code_to_name.get(ind_code, ind_code)\n",
    "        \n",
    "        results.append({\n",
    "            'Industry': industry_name,\n",
    "            'Code': ind_code,\n",
    "            'Initial Year': int(initial_year),\n",
    "            'Initial LS': initial_ls,\n",
    "            'Final Year': int(final_year),\n",
    "            'Final LS': final_ls,\n",
    "            'Change': change,\n",
    "            'Annual Growth (%)': annual_growth\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file.name}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "labor_share_table = pd.DataFrame(results)\n",
    "\n",
    "# Sort by initial labor share (descending)\n",
    "labor_share_table = labor_share_table.sort_values('Initial LS', ascending=False)\n",
    "\n",
    "print(f\"\\n✅ Processed {len(labor_share_table)} industries\")\n",
    "print(f\"\\nFirst 10 industries by initial labor share:\")\n",
    "print(labor_share_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LABOR SHARE STATISTICS BY INDUSTRY\n",
      "====================================================================================================\n",
      "\n",
      "Coverage: 1987-2018\n",
      "Number of industries: 56\n",
      "\n",
      "Industries with DECLINING labor share: 46 (82.1%)\n",
      "Industries with INCREASING labor share: 10 (17.9%)\n",
      "\n",
      "Median change: -0.0691\n",
      "Mean annual growth: -0.47%\n",
      "\n",
      "                                    Industry   Code  Initial Year  Initial LS  Final Year  Final LS  Change  Annual Growth (%)\n",
      "                                       711AS  711AS          1987      0.9711        2018    0.7670 -0.2041            -0.7582\n",
      "Computer systems design and related services   5415          1987      0.9632        2018    0.8607 -0.1024            -0.3621\n",
      "                                         621    621          1987      0.9361        2018    0.8677 -0.0684            -0.2443\n",
      "                                         624    624          1987      0.9326        2018    0.9496  0.0170             0.0582\n",
      "                                          23     23          1987      0.9240        2018    0.7979 -0.1261            -0.4723\n",
      "                              Legal services   5411          1987      0.9179        2018    0.6640 -0.2538            -1.0388\n",
      "                                          61     61          1987      0.9171        2018    0.8133 -0.1037            -0.3865\n",
      "                                       622HO  622HO          1987      0.8961        2018    0.8563 -0.0398            -0.1463\n",
      "                                         323    323          1987      0.8767        2018    0.6648 -0.2119            -0.8884\n",
      "                                         561    561          1987      0.8646        2018    0.8208 -0.0439            -0.1678\n",
      "                                         337    337          1987      0.8401        2018    0.8013 -0.0388            -0.1523\n",
      "                                         484    484          1987      0.8347        2018    0.7092 -0.1255            -0.5242\n",
      "                                         524    524          1987      0.8339        2018    0.5076 -0.3263            -1.5887\n",
      "                                         482    482          1987      0.8248        2018    0.5311 -0.2937            -1.4098\n",
      "                                         493    493          1987      0.8236        2018    0.8699  0.0463             0.1766\n",
      "                                       487OS  487OS          1987      0.8131        2018    0.7855 -0.0276            -0.1112\n",
      "                                       315AL  315AL          1987      0.8034        2018    0.9311  0.1277             0.4770\n",
      "                                      5412OP 5412OP          1987      0.7965        2018    0.7809 -0.0156            -0.0638\n",
      "                                       313TT  313TT          1987      0.7952        2018    0.7823 -0.0129            -0.0528\n",
      "                                         331    331          1987      0.7902        2018    0.5081 -0.2820            -1.4141\n",
      "                                          55     55          1987      0.7746        2018    0.8720  0.0974             0.3830\n",
      "                                          81     81          1987      0.7719        2018    0.8553  0.0834             0.3315\n",
      "                                         213    213          1987      0.7685        2018    0.6548 -0.1137            -0.5151\n",
      "                                         722    722          1987      0.7405        2018    0.7021 -0.0383            -0.1714\n",
      "                                         333    333          1987      0.7394        2018    0.6246 -0.1148            -0.5428\n",
      "                                         485    485          1987      0.7263        2018    0.7247 -0.0016            -0.0070\n",
      "                                         334    334          1987      0.7115        2018    0.5209 -0.1906            -1.0007\n",
      "                                         339    339          1987      0.7101        2018    0.6442 -0.0659            -0.3136\n",
      "                                         332    332          1987      0.7097        2018    0.6870 -0.0227            -0.1046\n",
      "                                Retail trade   44RT          1987      0.7064        2018    0.5962 -0.1102            -0.5458\n",
      "                                         327    327          1987      0.6931        2018    0.5000 -0.1931            -1.0480\n",
      "                                         321    321          1987      0.6912        2018    0.6350 -0.0562            -0.2732\n",
      "                                      3361MV 3361MV          1987      0.6812        2018    0.5076 -0.1736            -0.9442\n",
      "                                         562    562          1987      0.6650        2018    0.5827 -0.0823            -0.4254\n",
      "                                         326    326          1987      0.6616        2018    0.6029 -0.0587            -0.2993\n",
      "                                         335    335          1987      0.6481        2018    0.5784 -0.0698            -0.3666\n",
      "                                         483    483          1987      0.6451        2018    0.5200 -0.1251            -0.6930\n",
      "                                         212    212          1987      0.6418        2018    0.3254 -0.3164            -2.1676\n",
      "                                         721    721          1987      0.6308        2018    0.5010 -0.1298            -0.7402\n",
      "                                      3364OT 3364OT          1987      0.6232        2018    0.5332 -0.0900            -0.5019\n",
      "                                         481    481          1987      0.6059        2018    0.4397 -0.1662            -1.0291\n",
      "                                          42     42          1987      0.5869        2018    0.4591 -0.1278            -0.7890\n",
      "                                         322    322          1987      0.5866        2018    0.5204 -0.0662            -0.3853\n",
      "                                       113FF  113FF          1987      0.5788        2018    0.7836  0.2048             0.9820\n",
      "                                       111CA  111CA          1987      0.5780        2018    0.6453  0.0673             0.3558\n",
      "                                       311FT  311FT          1987      0.5149        2018    0.4534 -0.0615            -0.4097\n",
      "                                         325    325          1987      0.4477        2018    0.2814 -0.1663            -1.4868\n",
      "                                       521CI  521CI          1987      0.4450        2018    0.4001 -0.0449            -0.3426\n",
      "                                         324    324          1987      0.3897        2018    0.1071 -0.2826            -4.0813\n",
      "                                         512    512          1987      0.3686        2018    0.5689  0.2003             1.4097\n",
      "                                         513    513          1987      0.3560        2018    0.2507 -0.1053            -1.1246\n",
      "                                         211    211          1987      0.2672        2018    0.1449 -0.1223            -1.9544\n",
      "                                          22     22          1987      0.2468        2018    0.2648  0.0180             0.2273\n",
      "                                       532RL  532RL          1987      0.2006        2018    0.1619 -0.0386            -0.6878\n",
      "                                         531    531          1987      0.0823        2018    0.0672 -0.0151            -0.6528\n",
      "                                         525    525          1987      0.0409        2018    0.0900  0.0491             2.5761\n"
     ]
    }
   ],
   "source": [
    "# Display full table\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"LABOR SHARE STATISTICS BY INDUSTRY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nCoverage: {labor_share_table['Initial Year'].min()}-{labor_share_table['Final Year'].max()}\")\n",
    "print(f\"Number of industries: {len(labor_share_table)}\")\n",
    "print(f\"\\nIndustries with DECLINING labor share: {(labor_share_table['Change'] < 0).sum()} ({(labor_share_table['Change'] < 0).sum() / len(labor_share_table) * 100:.1f}%)\")\n",
    "print(f\"Industries with INCREASING labor share: {(labor_share_table['Change'] > 0).sum()} ({(labor_share_table['Change'] > 0).sum() / len(labor_share_table) * 100:.1f}%)\")\n",
    "print(f\"\\nMedian change: {labor_share_table['Change'].median():.4f}\")\n",
    "print(f\"Mean annual growth: {labor_share_table['Annual Growth (%)'].mean():.2f}%\")\n",
    "print(f\"\\n{labor_share_table.to_string(index=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LATEX TABLE GENERATED\n",
      "====================================================================================================\n",
      "\n",
      "✅ Saved to: /Users/mitchv34/Work/industry_skill_premium/documents/tables/labor_share_by_industry.tex\n",
      "\n",
      "Preview:\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\caption{Labor Share Statistics by Industry}\n",
      "\\label{tab:labor_share_by_industry}\n",
      "\\scriptsize\n",
      "\\begin{tabularx}{\\textwidth}{Xcccc}\n",
      "\\toprule\n",
      "Industry & Initial LS & Final LS & Change & Growth (\\%/yr) \\\\\n",
      "\\midrule\n",
      "\\multicolumn{5}{l}{\\textit{Largest Declines}} \\\\\n",
      "524 & 0.834 & 0.508 & -0.326 & -1.59 \\\\\n",
      "212 & 0.642 & 0.325 & -0.316 & -2.17 \\\\\n",
      "482 & 0.825 & 0.531 & -0.294 & -1.41 \\\\\n",
      "324 & 0.390 & 0.107 & -0.283 & -4.08 \\\\\n",
      "331 & 0.790 & 0.508 & -0.282 & -1.41 \\\\\n",
      "Legal services & 0.918 & 0.664 & -0.254 & -1.04 \\\\\n",
      "323 & 0.877 & 0.665 & -0.212 & -0.89 \\\\\n",
      "711AS & 0.971 & 0.767 & -0.204 & -0.76 \\\\\n",
      "327 & 0.693 & 0.500 & -0.193 & -1.05 \\\\\n",
      "334 & 0.711 & 0.521 & -0.191 & -1.00 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{5}{l}{\\textit{Most Stable / Increasing}} \\\\\n",
      "624 & 0.933 & 0.950 & 0.017 & 0.06 \\\\\n",
      "22 & 0.247 & 0.265 & 0.018 & 0.23 \\\\\n",
      "493 & 0.824 & 0.870 & 0.046 & 0.18 \\\\\n",
      "525 & 0.041 & 0.090 & 0.049 & 2.58 \\\\\n",
      "111CA & 0.578 & 0.645 & 0.067 & 0.36 \\\\\n",
      "81 & 0.772 & 0.855 & 0.083 & 0.33 \\\\\n",
      "55 & 0.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table for manuscript\n",
    "# Simplify for publication - group similar industries and show top/bottom performers\n",
    "\n",
    "def generate_latex_table(df, max_rows=20):\n",
    "    \"\"\"Generate LaTeX table code for manuscript\"\"\"\n",
    "    \n",
    "    # Select top declining and top stable/increasing\n",
    "    df_sorted = df.sort_values('Change')\n",
    "    top_declining = df_sorted.head(10)\n",
    "    top_stable = df_sorted.tail(10)\n",
    "    \n",
    "    # Combine\n",
    "    display_df = pd.concat([top_declining, top_stable])\n",
    "    \n",
    "    latex = r\"\"\"\\begin{table}[H]\n",
    "\\centering\n",
    "\\caption{Labor Share Statistics by Industry}\n",
    "\\label{tab:labor_share_by_industry}\n",
    "\\scriptsize\n",
    "\\begin{tabularx}{\\textwidth}{Xcccc}\n",
    "\\toprule\n",
    "Industry & Initial LS & Final LS & Change & Growth (\\%/yr) \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    # Add largest declines section\n",
    "    latex += r\"\\multicolumn{5}{l}{\\textit{Largest Declines}} \\\\\" + \"\\n\"\n",
    "    for _, row in top_declining.iterrows():\n",
    "        latex += f\"{row['Industry']} & {row['Initial LS']:.3f} & {row['Final LS']:.3f} & {row['Change']:.3f} & {row['Annual Growth (%)']:.2f} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex += r\"\\midrule\" + \"\\n\"\n",
    "    latex += r\"\\multicolumn{5}{l}{\\textit{Most Stable / Increasing}} \\\\\" + \"\\n\"\n",
    "    \n",
    "    # Add most stable/increasing section\n",
    "    for _, row in top_stable.iterrows():\n",
    "        latex += f\"{row['Industry']} & {row['Initial LS']:.3f} & {row['Final LS']:.3f} & {row['Change']:.3f} & {row['Annual Growth (%)']:.2f} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex += r\"\"\"\\bottomrule\n",
    "\\end{tabularx}\n",
    "\\begin{minipage}{\\textwidth}\n",
    "\\vspace{0.2cm}\n",
    "\\footnotesize\n",
    "\\textit{Notes:} Initial LS is labor share in initial year (typically 1987), Final LS is labor share in final year (typically 2018). \n",
    "Change is percentage point change. Growth is annualized percentage growth rate. \n",
    "Table shows 10 industries with largest declines and 10 most stable/increasing industries out of \"\"\" + str(len(df)) + r\"\"\" total industries.\n",
    "Labor share declining in \"\"\" + str((df['Change'] < 0).sum()) + r\"\"\" industries (\"\"\" + f\"{(df['Change'] < 0).sum() / len(df) * 100:.0f}\" + r\"\"\"\\%).\n",
    "\\end{minipage}\n",
    "\\end{table}\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "# Generate and save LaTeX\n",
    "latex_code = generate_latex_table(labor_share_table)\n",
    "\n",
    "# Save to file\n",
    "output_tex = ROOT / 'documents' / 'tables' / 'labor_share_by_industry.tex'\n",
    "output_tex.parent.mkdir(exist_ok=True, parents=True)\n",
    "with open(output_tex, 'w') as f:\n",
    "    f.write(latex_code)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"LATEX TABLE GENERATED\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n✅ Saved to: {output_tex}\")\n",
    "print(f\"\\nPreview:\\n\")\n",
    "print(latex_code[:1000] + \"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved to: /Users/mitchv34/Work/industry_skill_premium/data/results/labor_share_by_industry.csv\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Total industries: 56\n",
      "Declining labor share: 46 (82.1%)\n",
      "Increasing labor share: 10 (17.9%)\n",
      "\n",
      "Labor Share Statistics:\n",
      "  Mean initial: 0.6713\n",
      "  Mean final: 0.5906\n",
      "  Mean change: -0.0806\n",
      "  Median change: -0.0691\n",
      "  Mean annual growth: -0.472%\n",
      "  Median annual growth: -0.398%\n",
      "\n",
      "Largest decline: 524\n",
      "  Change: -0.3263\n",
      "\n",
      "Largest increase: 113FF\n",
      "  Change: 0.2048\n"
     ]
    }
   ],
   "source": [
    "# Also save CSV for reference\n",
    "output_csv = ROOT / 'data' / 'results' / 'labor_share_by_industry.csv'\n",
    "output_csv.parent.mkdir(exist_ok=True, parents=True)\n",
    "labor_share_table.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✅ CSV saved to: {output_csv}\")\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print('='*100)\n",
    "print(f\"\\nTotal industries: {len(labor_share_table)}\")\n",
    "print(f\"Declining labor share: {(labor_share_table['Change'] < 0).sum()} ({(labor_share_table['Change'] < 0).sum() / len(labor_share_table) * 100:.1f}%)\")\n",
    "print(f\"Increasing labor share: {(labor_share_table['Change'] > 0).sum()} ({(labor_share_table['Change'] > 0).sum() / len(labor_share_table) * 100:.1f}%)\")\n",
    "print(f\"\\nLabor Share Statistics:\")\n",
    "print(f\"  Mean initial: {labor_share_table['Initial LS'].mean():.4f}\")\n",
    "print(f\"  Mean final: {labor_share_table['Final LS'].mean():.4f}\")\n",
    "print(f\"  Mean change: {labor_share_table['Change'].mean():.4f}\")\n",
    "print(f\"  Median change: {labor_share_table['Change'].median():.4f}\")\n",
    "print(f\"  Mean annual growth: {labor_share_table['Annual Growth (%)'].mean():.3f}%\")\n",
    "print(f\"  Median annual growth: {labor_share_table['Annual Growth (%)'].median():.3f}%\")\n",
    "print(f\"\\nLargest decline: {labor_share_table.loc[labor_share_table['Change'].idxmin(), 'Industry']}\")\n",
    "print(f\"  Change: {labor_share_table['Change'].min():.4f}\")\n",
    "print(f\"\\nLargest increase: {labor_share_table.loc[labor_share_table['Change'].idxmax(), 'Industry']}\")\n",
    "print(f\"  Change: {labor_share_table['Change'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Manuscript Tables\n",
    "\n",
    "To generate all tables and figures for the manuscript Data Description section, run:\n",
    "\n",
    "```bash\n",
    "python scripts/data_processing/generate_manuscript_tables.py\n",
    "```\n",
    "\n",
    "This script uses the labor share data generated above and creates:\n",
    "- Aggregate summary statistics by decade\n",
    "- Industry-level trend correlations  \n",
    "- Labor share heterogeneity groups\n",
    "- Slope distribution figure\n",
    "\n",
    "All outputs are saved to `documents/tables/` and `documents/images/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
